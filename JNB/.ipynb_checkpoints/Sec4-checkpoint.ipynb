{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb47439-5d2a-4c50-91e1-ffa7c585f01e",
   "metadata": {},
   "source": [
    "# 4 - Computing Least Squares Solutions\n",
    "Computing a least squares solution involves many of the concepts covered in sections 2 and 3 such as matrix multiplication and matrix inverse. Thus there are efficient and inefficient ways to compute a least squares solution given the problem setup. More specifically, if the problem involves a PSD matrix then one can take advantage of the Cholesky decomposition methods which were shown to be advantageous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf085f2-b1da-42c1-9deb-9dbb00e69ab1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as la\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013b9ed-2adb-49ff-bcaa-761a0c87b119",
   "metadata": {},
   "source": [
    "## 4.1 - Ordinary Least Squares (OLS) \n",
    "For solution $S$ , data matrix $X$ and solution space $Y$:   \n",
    "<br>\n",
    "$$\\begin{aligned} XS &= Y \\\\ X^TXS &= X^TY \\\\ S &= (X^TX)^{-1}X^TY\\end{aligned}$$\n",
    " \n",
    "One can make use of the pseudo inverse of  $X$  as its dimensions are arbitrary and may be singular:   \n",
    "<br>\n",
    "$$\\begin{aligned} XS &= Y \\\\ X^+XS &= X^+Y \\\\ S &\\approx X^+Y\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bbe66-553b-4740-8a09-79c63cbe0182",
   "metadata": {},
   "source": [
    "### 4.1.1 - SciPy OLS\n",
    "To compute the ordinary least squares solution the pseudo inverse is used. This is done with the SciPy function `pinv()` from the `scipy.linalg` function base. More information on the `pinv()` function can be found on the SciPy documentation page [[9]](#ref9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f69a3e-3532-40cf-a674-296a7a306e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.67459005, 0.33554957],\n",
       "        [0.48042258, 0.86050783],\n",
       "        [0.64218228, 0.429431  ]]),\n",
       " array([1, 1, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.uniform(size = (3,2))\n",
    "Y = np.array([1,1,1])\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0216299-4943-4535-8ff1-1b66586c77f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99860208, 0.99970045, 1.00169257])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv = la.pinv(X)\n",
    "S = inv @ Y\n",
    "X @ S # approximate solution to y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8b6b6-8770-455a-b267-81fdd257ca47",
   "metadata": {},
   "source": [
    "### 4.1.2 - Python statsmodels Module\n",
    "As per the statsmodels documentation page [[11] statsmodels: Econometric and Statistical Modeling with Python](#ref11) \"statsmodels is a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration.\" As with the previous Python modules introduced, the tools we require can be imported with the call `import statsmodels.api as sm`. It should be noted that version 0.13.2 of the statsmodels module is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42830b08-ce82-4030-853d-33ca4cc87829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.2\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "print(sm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973f863-0968-49dd-a255-f9aacc352af9",
   "metadata": {},
   "source": [
    "Here the module is used to compute least square solutions. The functions `sm.OLS()` and `sm.GLS()` are used to compute the ordinary and generalized least square solutions.\n",
    "### 4.1.3 - statsmodels OLS\n",
    "Notice how the `OLS()` function produces the exact same result as the raw computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ac74e-03c1-4ae6-9370-7b6e8daeb1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99860208, 0.99970045, 1.00169257])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv2 = sm.OLS(Y, X).fit()\n",
    "inv2.fittedvalues # same approx solution as raw computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824b586-ea19-4f8c-b0f0-238caadcd0a6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "library(pracma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935ca53-d953-4d8b-be41-087f50f5dd5f",
   "metadata": {},
   "source": [
    "### 4.1.4 - R OLS \n",
    "Using the same technique as done in Python, the pseudo inverse is used to find the ordinary least squares solution. This is done with the R function `pinv()` from the pracma package. More information on the `pinv()` function can be found on the pracma documentation page [[10]](#ref10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aba54-09ca-42d4-aae9-d735ec31bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [,1]      [,2]\n",
      "[1,] 0.6745901 0.3355496\n",
      "[2,] 0.4804226 0.8605078\n",
      "[3,] 0.6421823 0.4294310\n",
      "[1] 1 1 1\n"
     ]
    }
   ],
   "source": [
    "# set up with same \"random\" data as Python example\n",
    "X <- matrix(c(0.67459005, 0.48042258, 0.64218228, 0.33554957, 0.86050783, 0.429431), ncol = 2)\n",
    "Y <- rep(1, 3)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7343d7-ca38-4930-9b63-cd671dec34e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [,1]\n",
      "[1,] 0.9986021\n",
      "[2,] 0.9997004\n",
      "[3,] 1.0016926\n"
     ]
    }
   ],
   "source": [
    "inv <- pinv(X)\n",
    "S <- inv %*% Y\n",
    "print(X %*% S) # approximate solution to y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620b00e-e700-4493-b2b5-2b18e90138e4",
   "metadata": {},
   "source": [
    "These results are consistent with the computations done in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1db5af-3bbf-444b-b1ab-d7b5cfb15cf8",
   "metadata": {},
   "source": [
    "## 4.2 - Generalized Least Squares (GLS)\n",
    "GLS makes use of the PSD inverse calculations and matrix multiplication functions.\n",
    "For solution $S$, data matrix $X$, solution space $Y$ and PSD matrix $\\Sigma$:   \n",
    "<br>\n",
    "$$\\begin{aligned} XS &= Y \\\\ X^T\\Sigma^{-1}XS &= X^T\\Sigma^{-1}Y \\\\ S &= (X^T\\Sigma^{-1}X)^{-1}X^T\\Sigma^{-1}Y\\end{aligned}$$\n",
    "Since $\\Sigma$ is PSD, then $\\Sigma^{-1}$ is PSD and hence $(X^T\\Sigma^{-1}X)$ is also PSD. Thus using Cholesky decomposition for $\\Sigma = L_1^TL_1$ and the inner matrix $(X^T\\Sigma^{-1}X) = X^T(L_1^{-1}L_1^{-T})X = L_2^{T}L_2$ the GLS computation then becomes:  \n",
    "<br>\n",
    "$$\\begin{aligned} S &= (X^T\\Sigma^{-1}X)^{-1}X^T\\Sigma^{-1}Y \\\\ &= (L_2^{-1}L_2^{-T})X^T(L_1^{-1}L_1^{-T})Y\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07766607-c853-48d3-9da5-08460f534b50",
   "metadata": {},
   "source": [
    "### 4.2.1 - Python GLS \n",
    "The shortcuts discussed above for PSD matrices can be used directly in the GLS computation. One can implement a version that uses Cholesky decomposition methods, as well as a \"pure\" version which does not, and finally a built-in method using the statsmodels module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a0e2f-7d9f-4eef-ae5a-dd11956f2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fast generalized least squares solution for data matrix X, solution space Y and PSD matrix sigma.\n",
    "# The function computes X(X^Tsigma^{-1}X)^{-1}X^Tsigma^{-1}Y\n",
    "# Notes: -> sigma must be PSD\n",
    "#        -> dimensions of X, Y and sigma must agree for matrix multiplication\n",
    "def chole_gls(X, Y, sigma):\n",
    "    \n",
    "    # Find first inverse sigma^{-1}\n",
    "    L = la.solve_triangular(np.linalg.cholesky(sigma), np.eye(len(sigma)), lower=True)\n",
    "    \n",
    "    # Find next inverse (...)^{-1}\n",
    "    inner = X.T @ np.matmul(L.T,L)\n",
    "    L2 = la.solve_triangular(np.linalg.cholesky(inner @ X), np.eye(len(X)), lower=True)\n",
    "    \n",
    "    # Return gls\n",
    "    return np.matmul(L2.T,L2) @ inner @ Y\n",
    "\n",
    "\n",
    "# A pure generalized least squares solution for data matrix X, solution space Y and PSD matrix sigma.\n",
    "# The function computes X(X^Tsigma^{-1}X)^{-1}X^Tsigma^{-1}Y\n",
    "# Notes: -> sigma must be PSD\n",
    "#        -> dimensions of X, Y and sigma must agree for matrix multiplication\n",
    "def pure_gls(X, Y, sigma):\n",
    "    \n",
    "    # Find first inverse sigma^{-1}\n",
    "    s_inv = la.inv(sigma)\n",
    "\n",
    "    # Return gls\n",
    "    return la.inv(X.T @ s_inv @ X) @ X.T @ s_inv @ Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3740ff6-5a88-4677-972e-2d5fef4433e6",
   "metadata": {},
   "source": [
    "A small GLS example is performed below using a matrix of size $\\mathbb{R}^{3 \\times 3}$ where all three methods are tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984d010-87f0-44f3-953a-f178d91b3d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.05154553, 0.33478251, 0.68424231],\n",
       "        [0.7103685 , 0.42704954, 0.5659001 ],\n",
       "        [0.6738195 , 0.29515479, 0.28922683]]),\n",
       " array([1., 1., 1.]),\n",
       " array([[1.14032497, 1.0809451 , 1.22701868],\n",
       "        [1.0809451 , 1.33186762, 1.04385891],\n",
       "        [1.22701868, 1.04385891, 1.86092279]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "x = np.random.uniform(0,1, size = (3,3))\n",
    "y = np.array([1.,1,1])\n",
    "# PSD sigma matrix\n",
    "s = np.random.uniform(0,1, size = (3,3)) # symmetric psd\n",
    "s = s + s.T - np.diag(s.diagonal())\n",
    "s = np.matmul(s,s.T)/3\n",
    "x,y,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed52228-04cf-4c49-b8a2-fb42508ad0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1.]), array([1., 1., 1.]), array([1., 1., 1.]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln = pure_gls(x, y, s)\n",
    "soln_chole = chole_gls(x,y,s)\n",
    "soln_sm = sm.GLS(y, x, s).fit()\n",
    "x @ soln, x @ soln_chole, soln_sm.fittedvalues # 3 solutions all equal to y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc794f-178a-4f59-892a-51a2df884929",
   "metadata": {},
   "source": [
    "One can observe that the results are all equivalent for each method. To view the difference in computational run times for each of these methods, a small experiment is run using varying sized matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ed4d2-204f-4151-8253-4f1e24a46207",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.array([2, 10, 50, 500, 1000, 5000, 10000])\n",
    "n = len(N)\n",
    "\n",
    "# data \n",
    "X = np.random.uniform(0,1, size = (N[n-1], N[n-1]))\n",
    "Y = np.ones(N[n-1])\n",
    "# psd sigma\n",
    "sigma = np.random.uniform(0,1, size = (N[n-1], N[n-1]))\n",
    "sigma = 0.5*(sigma + sigma.T)\n",
    "sigma = sigma + N[n-1] * np.eye(N[n-1])\n",
    "    \n",
    "time_normal = []\n",
    "time_chole = []\n",
    "time_sm = []\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    t1 = time.time()\n",
    "    sol1 = pure_gls(X[0:N[i], 0:N[i]], Y[0:N[i]], sigma[0:N[i], 0:N[i]])\n",
    "    time_normal.append(time.time()-t1)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    sol2 = chole_gls(X[0:N[i], 0:N[i]], Y[0:N[i]], sigma[0:N[i], 0:N[i]])\n",
    "    time_chole.append(time.time()-t2)\n",
    "    \n",
    "    t3 = time.time()\n",
    "    sol3 = sm.GLS(Y[0:N[i]], X[0:N[i], 0:N[i]], sigma[0:N[i], 0:N[i]]).fit()\n",
    "    time_sm.append(time.time()-t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81786492-c260-4c62-9a88-4ddb4e8d5c69",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059f\" style='display:inline'><caption>Computational Runtime (seconds)</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >N for NxN sized matrix</th>        <th class=\"col_heading level0 col1\" >Pure GLS</th>        <th class=\"col_heading level0 col2\" >Cholesky GLS</th>        <th class=\"col_heading level0 col3\" >statsmodels GLS</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow0_col0\" class=\"data row0 col0\" >10</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow0_col1\" class=\"data row0 col1\" >0.000081</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow0_col2\" class=\"data row0 col2\" >0.000589</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow0_col3\" class=\"data row0 col3\" >0.000398</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow1_col0\" class=\"data row1 col0\" >50</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow1_col1\" class=\"data row1 col1\" >0.000610</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow1_col2\" class=\"data row1 col2\" >0.001257</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow1_col3\" class=\"data row1 col3\" >0.001597</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow2_col0\" class=\"data row2 col0\" >500</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow2_col1\" class=\"data row2 col1\" >0.630047</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow2_col2\" class=\"data row2 col2\" >0.020646</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow2_col3\" class=\"data row2 col3\" >0.497284</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow3_col0\" class=\"data row3 col0\" >1000</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow3_col1\" class=\"data row3 col1\" >3.008091</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow3_col2\" class=\"data row3 col2\" >0.069500</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow3_col3\" class=\"data row3 col3\" >2.308699</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow4_col0\" class=\"data row4 col0\" >5000</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow4_col1\" class=\"data row4 col1\" >11.976236</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow4_col2\" class=\"data row4 col2\" >3.500787</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow4_col3\" class=\"data row4 col3\" >65.164299</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow5_col0\" class=\"data row5 col0\" >10000</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow5_col1\" class=\"data row5 col1\" >21.954963</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow5_col2\" class=\"data row5 col2\" >15.347694</td>\n",
       "                        <td id=\"T_44120f36_0dd1_11ed_9477_b03af2b6059frow5_col3\" class=\"data row5 col3\" >545.324912</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6e21452b90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'N for NxN sized matrix':N[1:], \n",
    "                   \"Pure GLS\":time_normal[1:], \n",
    "                   \"Cholesky GLS\":time_chole[1:], \n",
    "                   \"statsmodels GLS\":time_sm[1:]})\n",
    "df.style.hide_index().set_table_attributes(\"style='display:inline'\").set_caption('Computational Runtime (seconds)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a994944-930f-4875-81ae-5a85cc11d760",
   "metadata": {},
   "source": [
    "Note: these runtimes will vary depending on the machine one uses but we can expect the overall trends to stay the same. One can observe how much slower the built-in statsmodels function `sm.GLS()` is compared to the other two methods. This can be attributed to additional tasks performed by the statsmodels function within the `GLS()` call. These tasks include calculating residuals, fitted values, and other descriptive summary results. If your goal is to produce nice results and you are not concerned with run time, then the use of this function may be desired. If run time is a concern, then building GLS functions from scratch is clearly advantageous. These raw functions can be improved by implementing a Cholesky decomposition method, which was shown above to compute solutions the fastest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9b27f-9052-4456-9d54-299c5832073c",
   "metadata": {},
   "source": [
    "### 4.2.2 - R GLS \n",
    "The same process for GLS computation can be carried out in R, making use of the same PSD matrix tricks. It should be noted that matrix multiplication is slightly slower in R compared to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b010f9c-56b0-49cd-8129-05ea7a22f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fast generalized least squares solution for data matrix X, solution space Y\n",
    "# and PSD matrix sigma. The function computes (X^Tsigma^{-1}X)^{-1}X^Tsigma^{-1}Y\n",
    "# Notes: -> sigma must be PSD\n",
    "#        -> dimensions of X, Y and sigma must agree for matrix multiplication\n",
    "chole_gls <- function(X,Y,sigma) {\n",
    "  \n",
    "  # sigma inverse\n",
    "  Linv <- backsolve(chol(sigma), diag(ncol(X)))\n",
    "  \n",
    "  # inner inverse\n",
    "  inner <- crossprod(tcrossprod(Linv), X)\n",
    "  L2 <- backsolve(chol(crossprod(inner, X)), diag(ncol(X)))\n",
    "  \n",
    "  # return gls soln\n",
    "  tcrossprod(tcrossprod(L2), inner) %*% Y\n",
    "}\n",
    "\n",
    "\n",
    "# A pure generalized least squares solution for data matrix X, solution space Y\n",
    "# and PSD matrix sigma. The function computes (X^Tsigma^{-1}X)^{-1}X^Tsigma^{-1}Y\n",
    "# Notes: -> sigma must be PSD\n",
    "#        -> dimensions of X, Y and sigma must agree for matrix multiplication\n",
    "pure_gls <- function(X, Y, sigma) {\n",
    "  \n",
    "  # sigma inverse\n",
    "  inv1 <- solve(sigma)\n",
    "  \n",
    "  # inner inverse\n",
    "  inv2 <- solve(t(X) %*% inv1 %*% X)\n",
    "  \n",
    "  # return gls\n",
    "  inv2 %*% t(X) %*% inv1 %*% Y\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5a93d-306f-4582-b977-2e7f1dadda11",
   "metadata": {},
   "source": [
    "Similar to what was done above for Python, a small GLS example is performed below using a matrix of size $\\mathbb{R}^{3 \\times 3}$. Here the Cholesky method is implemented and compared to a \"pure\" implementation that uses no decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a96558-4fd7-4627-a278-90260980f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [,1]       [,2]      [,3]\n",
      "[1,] 0.9049013 0.14480767 0.5152959\n",
      "[2,] 0.7297637 0.40634528 0.2310326\n",
      "[3,] 0.2044630 0.04217148 0.5226685\n",
      "[1] 1 1 1\n",
      "          [,1]      [,2]      [,3]\n",
      "[1,] 3.4516124 0.5254392 0.7363178\n",
      "[2,] 0.5254392 3.2415333 0.8283556\n",
      "[3,] 0.7363178 0.8283556 3.3701677\n"
     ]
    }
   ],
   "source": [
    "x <- matrix(runif(9), ncol = 3)\n",
    "y <- c(1,1,1)\n",
    "s <- matrix(runif(9), ncol = 3)\n",
    "s <- 0.5*(s + t(s))\n",
    "s <- s + 3*eye(3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab054307-5fcc-4a77-976d-daabc7ad0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     [,1]\n",
      "[1,]    1\n",
      "[2,]    1\n",
      "[3,]    1\n",
      "     [,1]\n",
      "[1,]    1\n",
      "[2,]    1\n",
      "[3,]    1\n"
     ]
    }
   ],
   "source": [
    "soln1 <- pure_gls(x,y,s)\n",
    "soln2 <- chole_gls(x,y,s)\n",
    "print(x %*% soln1)\n",
    "print(x %*% soln2) # same solution equal to y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe4a40-e26d-4acc-9bcb-a69308ea7472",
   "metadata": {},
   "source": [
    "One can observe the equivalence os the solutions for each method. To view the difference in computational run times for each of these methods, a small experiment is run using varying sized matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03915a38-f042-4250-8c71-0f81a7408b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales <- c(2, 10, 50, 500, 1000, 5000, 10000)\n",
    "n <- length(scales)\n",
    "time_solve <- numeric(n)\n",
    "time_chol <- numeric(n)\n",
    "X <- matrix(runif(scales[n]^2, 0, 1), nrow = scales[n], ncol = scales[n])\n",
    "Y <- rep(1, scales[n])\n",
    "\n",
    "s <- matrix(runif(scales[n]^2, 0, 1), nrow = scales[n], ncol = scales[n])\n",
    "s <- 0.5 * (t(s) + s)\n",
    "s <- s + scales[n] * eye(scales[n])\n",
    "\n",
    "for (i in 1:n) {\n",
    "  N <- scales[i]\n",
    "  \n",
    "  t1 <- Sys.time()\n",
    "  soln1 <- pure_gls(X[1:N, 1:N], Y[1:N], s[1:N, 1:N])\n",
    "  time_solve[i] <- Sys.time() - t1\n",
    "  \n",
    "  t3 <- Sys.time()\n",
    "  soln2 <- chole_gls(X[1:N, 1:N], Y[1:N], s[1:N, 1:N])\n",
    "  time_chol[i] <- Sys.time() - t3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6471513-f542-48f1-b19f-4e82e756148a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 6 x 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>N for NxN sized matrix</th><th scope=col>Pure Implementation</th><th scope=col>Cholesky Implementation</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>   10</td><td> 0.000717</td><td> 0.000070</td></tr>\n",
       "\t<tr><td>   50</td><td> 0.001714</td><td> 0.000257</td></tr>\n",
       "\t<tr><td>  500</td><td> 1.063931</td><td> 0.069808</td></tr>\n",
       "\t<tr><td> 1000</td><td> 2.827480</td><td> 0.168958</td></tr>\n",
       "\t<tr><td> 5000</td><td>13.069145</td><td> 3.751185</td></tr>\n",
       "\t<tr><td>10000</td><td>33.688865</td><td>16.694152</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 x 3 of type dbl\n",
       "\\begin{tabular}{lll}\n",
       " N for NxN sized matrix & Pure Implementation & Cholesky Implementation\\\\\n",
       "\\hline\n",
       "\t    10 &  0.000717 &  0.000070\\\\\n",
       "\t    50 &  0.001714 &  0.000257\\\\\n",
       "\t   500 &  1.063931 &  0.069808\\\\\n",
       "\t  1000 &  2.827480 &  0.168958\\\\\n",
       "\t  5000 & 13.069145 &  3.751185\\\\\n",
       "\t 10000 & 33.688865 & 16.694152\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 x 3 of type dbl\n",
       "\n",
       "| N for NxN sized matrix | Pure Implementation | Cholesky Implementation |\n",
       "|---|---|---|\n",
       "|    10 |  0.000717 |  0.000070 |\n",
       "|    50 |  0.001714 |  0.000257 |\n",
       "|   500 |  1.063931 |  0.069808 |\n",
       "|  1000 |  2.827480 |  0.168958 |\n",
       "|  5000 | 13.069145 |  3.751185 |\n",
       "| 10000 | 33.688865 | 16.694152 |\n",
       "\n"
      ],
      "text/plain": [
       "     N for NxN sized matrix Pure Implementation Cholesky Implementation\n",
       "[1,]    10                   0.000717            0.000070              \n",
       "[2,]    50                   0.001714            0.000257              \n",
       "[3,]   500                   1.063931            0.069808              \n",
       "[4,]  1000                   2.827480            0.168958              \n",
       "[5,]  5000                  13.069145            3.751185              \n",
       "[6,] 10000                  33.688865           16.694152              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res <- cbind(scales, round(time_solve, 6), round(time_chol, 6))\n",
    "colnames(res) <- c('N for NxN sized matrix', \"Pure Implementation\", 'Cholesky Implementation')\n",
    "res[2:7,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3482c1-da9c-424e-b489-8aafccd6c8cb",
   "metadata": {},
   "source": [
    "Note: these runtimes will vary depending on the machine one uses but we can expect the overall trends to stay the same. The results are similar to what was found in Python. Taking advantage of a Cholesky decomposition when computing a GLS solution in R clearly leads to faster run times. The difference in run time appears to get larger as the size of the system increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084beb0e-4b94-4df5-9806-5332aedd1d7c",
   "metadata": {},
   "source": [
    "#   \n",
    "#    \n",
    "#    \n",
    "***\n",
    "***\n",
    "[9] Virtanen, P. et al., 2020. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python, [[link]](https://scipy.org/) <a class=\"anchor\" id=\"ref9\"></a>   \n",
    "[10] Hans W. Borchers, 2022, Package 'pracma' (Practical Numerical Math Functions), [[link]](https://CRAN.R-project.org/package=pracma) <a class=\"anchor\" id=\"ref10\"></a>    \n",
    "[11] Seabold, Skipper, and Josef Perktold, 2010. statsmodels: Econometric and Statistical Modeling with Python, [[link]](https://www.statsmodels.org) <a class=\"anchor\" id=\"ref11\"></a>   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
